# ğŸš€ SEO Automation Pipeline mit OpenAI & Retrieval (RAG)

Dieses Projekt bietet eine **komplette End-to-End-Pipelines fÃ¼r die SEO-Optimierung von Websites**, inklusive **Web-Crawling, SEO-Analyse, KI-gestÃ¼tzter Text-Optimierung und QualitÃ¤tskontrolle**.

Kern des Projekts sind **automatisierte AblÃ¤ufe**, die von der **Datengewinnung bis zur SEO-optimierten Textgenerierung** reichen.
Es wird eine pipeline zur Text-Optimierung Mithilfe von **OpenAI (ChatGPT)** hergestellt. Die Textelemente eines HTML Dokumentes werden mit ChatGPT SEO optimiert und danach wieder in den code eingebaut.
Der Kunde erhÃ¤lt eine Datei als Vorschau auf seine SEO optimierte website.

## ğŸ“š Inhaltsverzeichnis

- Features
- Projektstruktur
- Ablauf & Module
- Technologien
- Installation
- Nutzung
- Ziele
- Roadmap

## âœ… Features

- ğŸŒ **Automatisiertes Web Crawling** (inkl. Filter fÃ¼r relevante Inhalte)
- âœï¸ **Generierung von SEO-optimierten Texten** mithilfe der OpenAI API
- ğŸ§  **RAG-gestÃ¼tzte Fehlererkennung & Textkorrektur** mit Vektordatenbank (FAISS)
- ğŸ“Š **Analyse der Optimierungsergebnisse** (Statistiken, Ã„hnlichkeiten, Visualisierungen)
- ğŸ“ˆ **Keyword-Analyse und Keyword-Optimierung**
- ğŸ“¦ Ausgabe in **HTML und PDF** fÃ¼r Kunden
- ğŸ“Š Umfangreiche **Datenvisualisierungen** (Wordclouds, Cosine Similarity, Keyword-Verteilung)




<img src="https://drive.google.com/uc?id=10oR2bcugvN2MClp14ia7gnzMGX5b896t" alt="SEO Heatmap" width="600">




## ğŸ—‚ï¸ Projektstruktur

```
SEO-Project/
â”œâ”€â”€ data/                # Prompts, Fehler-Korrektur-Daten, weitere JSON Dateien
â”œâ”€â”€ notebooks/           # Colab/Notebooks zum Starten und Entwickeln
â”œâ”€â”€ output/              # Erzeugte Dateien (HTML, PDF, Bilder)
â”‚   â”œâ”€â”€ final           # Dokumente fÃ¼r Kunden (HTML, PDF)
â”‚   â””â”€â”€ images          # Visualisierungen
â”œâ”€â”€ src/                # Source Code (Python-Klassen und Module)
â”‚   â”œâ”€â”€ webscraper.py    # Webscrawling und Text-Extraktion
â”‚   â”œâ”€â”€ llmprocessor.py # Anbindung an OpenAI API, Keyword Extraktion
â”‚   â”œâ”€â”€ chatbot.py       # Zentrale Chatbot-Klasse zur Kommunikation mit GPT
â”‚   â”œâ”€â”€ seoanalyzer.py   # Analyse und Auswertung der Texte
â”‚   â”œâ”€â”€ github.py        # Automatischer Upload ins GitHub Repo
â”‚   â”œâ”€â”€ utils.py         # Hilfsmodule (z.B. fÃ¼r Prompt-Management)
â”‚   â””â”€â”€ embeddingdemo.py# 3D Embedding- und Cosine Similarity Visualisierungen
â”œâ”€â”€ tests/              # pytest der HauptfunktionalitÃ¤ten
â””â”€â”€ requirements.txt    # Python-AbhÃ¤ngigkeiten
```

## âš™ï¸ Ablauf & Module

### 1. **Web Crawling**
- **src/webscraper.py**: Holt Inhalte von Webseiten, filtert irrelevante Seiten (z.B. Impressum, AGB).

### 2. **SEO-Optimierung mit OpenAI**
- **src/llmprocessor.py**:
  - Extrahiert Keywords aus den Inhalten.
  - Optimiert die Texte fÃ¼r SEO mit gezielten Prompts.

### 3. **Analyse & Visualisierung**
- **src/seoanalyzer.py**: Verarbeitet und analysiert die Original- und optimierten Texte.

### 4. **GitHub Automation**
- **src/github.py**: LÃ¤dt finale Ergebnisse in ein GitHub-Repo hoch.

## ğŸ§° Technologien

| Technologie                  | Beschreibung                                       |
|-----------------------------|---------------------------------------------------|
| Python                      | Hauptsprache                                       |
| OpenAI API (ChatGPT, GPT-4)  | Generative KI fÃ¼r SEO-Texte                       |
| FAISS                      | Vektorsuche fÃ¼r RAG und Text-Fehler                |
| Pandas, NumPy               | Datenanalyse und Verarbeitung                      |
| Matplotlib, Seaborn         | Visualisierungen                                   |
| Sentence Transformers       | Embedding-Erstellung fÃ¼r Vektordatenbank          |
| BeautifulSoup, Requests     | Webcrawling                                        |
| Google Colab                | Entwicklung und AusfÃ¼hrung                        |

## ğŸš€ Installation

```bash
pip install -r requirements.txt
python -m spacy download de_core_news_sm
pip install faiss-cpu sentence-transformers openai wordcloud matplotlib seaborn
```

## ğŸ’» Nutzung

```python
scraper = WebsiteScraper(start_url="https://www.example.com")
scraper.scrape_website()

llm_processor = LLMProcessor(prompts_folder, get_filtered_texts, google_ads_keywords)
llm_processor.run_all()

seo_analyzer = SEOAnalyzer(seo_json, original_texts, keywords_final)
seo_analyzer.run_analysis()
```

## ğŸ¯ Ziele

- âœ… VollstÃ¤ndige Automatisierung der SEO-Optimierung
- âœ… RAG fÃ¼r sprachliche QualitÃ¤tskontrolle
- âœ… Kundenfertige PDF/HTML-Reports

## ğŸš§ Roadmap

- [ ] **Produkt fÃ¼r Kunden finalisieren:** all-in-one solution fÃ¼r webcrawl + SEO + optimierten html code
- [ ] Automatische SEO Scores (z.B. Google Ads API)
- [ ] Automatische Keyword-Erweiterung
- [ ] Mehrsprachigkeit
- [ ] WordPress-Integration
